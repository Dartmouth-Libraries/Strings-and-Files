{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d171187f",
   "metadata": {},
   "source": [
    "# Text Analysis in Python 1: Working with Strings & Files\n",
    "\n",
    "<h1 style=\"text-align:center;font-size:300%;\">The State of the Union is ... long?</h1> \n",
    "  <!--<img src=\"https://miro.medium.com/max/720/1*pp7HX01jBv2wbVRW9Ml_mA.png\" style=\"width:%80;\">-->\n",
    "  <img src = \"https://cdn.theatlantic.com/thumbor/7G7_MhUOYg6M8JGSmbQCVoaJ-kY=/126x0:1794x938/1536x864/media/img/2015/01/16/opener_words/original.jpg\">\n",
    "\n",
    "## THE TEXT ANALYSIS IN PYTHON SERIES\n",
    "**How can we use computational techniques to analyze texts and then visualize patterns buried within them?** \n",
    "\n",
    "In this six-lesson series, you will learn how to get started with the Python programming language and how to apply Python to perform digital text analysis. You will practice identifying and visualizing patterns within individual texts and across large collections or corpora of texts.\n",
    "\n",
    "## Lesson 1: Working with Strings and Files\n",
    "\n",
    "**What can we learn about texts by applying text analysis in Python? How do we get started?**\n",
    "\n",
    "In this session, participants will:\n",
    "\n",
    "+ Learn how to write basic scripts in Python using Jupyter Notebooks\n",
    "+ Work with and modify strings and text files using Python\n",
    "+ Iterate through a corpus of texts, extract basic information from each, and create a colorful bar chart showing the changing lengths of State of the Union speeches\n",
    "\n",
    "## For First-Time, Novice, and Intermediate Programmers\n",
    "This tutorial will offer a basic introduction to performing text analysis in Python. It is designed for researchers (of all levels) interested in an introduction to text analysis with Python (no prior knowledge necessary). These **Jupyter Notebooks** are designed to work for both novice and intermediate users. First-time and beginner users of Python and Jupyter are recommended to complete the sections marked with **Python Basics** after the completion of the lesson. The lesson itself will focus on providing the code and basic skills you need to get started with text analysis. \n",
    "\n",
    "## Structure of Notebooks\n",
    "\n",
    "These Jupyter Notebooks are designed to integrate instructions and explanations (in the white \"markdown\" cells below) with hands-on practice with the code (in the gray \"code\" cells below).\n",
    "\n",
    "<h3 style=\"color:green\">Code Together:</h3><p style=\"color:green\">In these cell blocks, we will code together. You can find the completed version in our shared folder (ending with \"_completed.ipynb\").</p>\n",
    "\n",
    "<h3 style=\"color:blue;\">Exercises:</h3><p style=\"color:blue\">are in blue text. These are a chance to practice what you have learned.</p>\n",
    "\n",
    "<h3 style=\"color:purple\">Python Basics - Additional Practice</h3><p style=\"color:purple\">are in purple text. Work on these after the lesson if you would like more practice.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6e6b7",
   "metadata": {},
   "source": [
    "## Can't you just read the books the old-fashioned way? \n",
    "\n",
    "### Why code?\n",
    "\n",
    "<!--+ **accessibility**: learning to work with huge amount of data-->\n",
    "+ **scale-ability**: scale up from one paragraph to a million books\n",
    "+ **automate** the tedious; spend more time on the fun stuff\n",
    "+ **reproducibility**: do it once, do it a thousand times\n",
    "    + **Reproducible Research**: Also increasing calls, especially in Sciences, for data to be published with research so that other scholars can reproduce and test their results\n",
    "\t<!--+ Reproducing exact results in the humanities is probably both impossible and antithetical to humanities research. Nonetheless, there is a movement for humanities people to publish and preserve their \"datasets\". As an Indigenous Studies scholar, I think this is especially important as the most accessible texts and sources are often the most problematic and many scholars spend years uncovering alternative accounts or analyzing well-known accounts in more critical ways. Why not allow young scholars to build off your work and then take it further?-->\n",
    "+ **flexibility**: only limit on your choices is your imagination\n",
    "    + As opposed to out-of-the-box software that limits you to the imagination and constraints of the software developers\n",
    "+ **affordability**: free to run,\n",
    "+ **transferability**: convert files from one system to another\n",
    "    + Many forms of proprietary software push the user to save their data in data formats that only that software can read\n",
    "+ **longevity**: work with plain text files and .csvs will enhance the likelihood your data can still be read and processed 20, 40 years from now\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f09c3",
   "metadata": {},
   "source": [
    "### Why text analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965c75c",
   "metadata": {},
   "source": [
    "## Why do Text Analysis with Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7d27a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ea36997",
   "metadata": {},
   "source": [
    "## This Tutorial\n",
    "\n",
    "In this tutorial and notebook, you will practice working with a dataset or corpus of a well-known series of texts: the yearly State of the Union addresses given by Presidents of the United States since 1790."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df5d9b",
   "metadata": {},
   "source": [
    "\n",
    "## Part I. Setup\n",
    "\n",
    "### Downloading and Saving Dataset(s)\n",
    "\n",
    "1. Find the Class folder of code and data at ????.\n",
    "2. Save this folder in an easy to find place on your own computer (suggestion: save it \n",
    "\n",
    "### Getting Started with Course Jupyter Notebooks\n",
    "\n",
    "There are two main types of cells in Jupyter. This is a **markdown** cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb557a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code cell.\n",
    "# To comment out a line, add a # at the beginning\n",
    "\n",
    "print(\"Hello world my name is XXX!\")  #replace \"XXX\" with your name\n",
    "print(\"This is the line seemingly every intro programming lesson begins with.\")\n",
    "#To run the code in this cell, hit CTRL + ENTER or click on the Run/Play button at the top of the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7163fb",
   "metadata": {},
   "source": [
    "To create new cells below this one, select **Insert (tab) --> Cell below** or **type ESC + B**. To add new cells above this one, select **Insert --> Cell above** or **type ESC + A**. To change a coding cell (for the machine to read) to a text / markdown cell (with notes or instructions for humans), select **Cell --> Cell Type --> Markdown** or type **ESC + M**. To do the opposite, select **Cell --> Cell Type --> Code** or type **ESC + Y**. You may also add, delete, or change cells using the menu options above. For more keyboard shortcuts see click on the **Help tab above --> Keyboard Shortcuts** (or just type **ESC + H**).\n",
    "\n",
    "<h3 style=\"color:blue;\">Exercise: Create New Coding Cells / Practice with Basic Python</h3>\n",
    "\n",
    "<p style=\"color:blue;\">Please create some new coding cells below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8101b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to begin with some basic Python, let's first assign a number to a variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then apply some additional math to that variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86c9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create some simple strings (in this case sentences) and assign them to variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6703425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the strings (sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of people names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54682c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an item to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the lists you have created\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc324667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine and print the lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd98c5",
   "metadata": {},
   "source": [
    "## Part II: Importing Python Packages or Libraries\n",
    "\n",
    "Before beginning, we need to import some packages. Often, we need to install and import customized Python packages (sometimes called \"modules\") in addition to the core functions (like **print()**, **len()**, **sum()**, and others).\n",
    "\n",
    "[ADD COMMENT ABOUT INSTALLING PACKAGES, DEPENDING ON THE THE SETUP WE HAVE FOR STUDENTS TO USE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa793faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, glob #the os package allows us to navigate through the files on our own computers\n",
    "from pathlib import Path #the pathlib package helps us work with file paths\n",
    "#for more on using pathlib see: https://builtin.com/software-engineering-perspectives/python-pathlib\n",
    "import nltk,re #we can import multiple packages on one line using commas to separate new package names\n",
    "#import matplotlib as plt   #matplotlib and seaborn are used here to create graphs, charts, and other visualizations\n",
    "import matplotlib.pyplot as plt #needed for xticks\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 10]  #changes default figure size to make larger plots\n",
    "\n",
    "%config InteractiveShellApp.matplotlib = 'inline'\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "#Press CTRL+Enter to run this codeblock! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9392def",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\"> Code Together:</h3>\n",
    "\n",
    "<p style=\"color:green\">We will also need to use the \"collections\" package as well. Let's import that in the code cell below:</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: when importing packages, Python will only print something out if there is an error. \n",
    "\n",
    "\n",
    "#Press CTRL+Enter to run this codeblock!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc78e5",
   "metadata": {},
   "source": [
    "# Part III: Navigating through your computer's files and folders\n",
    "\n",
    "1. To work with the State of the Union addresses you downloaded (hereafter: SOTU), we will need to navigate to the folder you placed them in. First, check the \"current working directory\" that Python is working with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362ef692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\F0040RP\\Documents\\DartLib_RDS\\textAnalysis\\strings-and-files\n"
     ]
    }
   ],
   "source": [
    "#note: to navigate through your files we will be using the Python library pathlib, which has become the preferred package \n",
    "#   for this task. However, I will also include the code for using the more traditional method (with the package os), \n",
    "#   but commented out.\n",
    "print(Path.cwd())\n",
    "#print(os.getcwd()) \n",
    "\n",
    "#Press CTRL+Enter to run this codeblock! This is the last time this reminder will be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f9ad3a",
   "metadata": {},
   "source": [
    "2. Your current working directory, printed out in the previous step, should be the location where you saved this notebook. Before moving on, double-check to make sure that you also saved the \"sotu\" folder of texts in that same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8554af50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/F0040RP/Documents/DartLib_RDS/textAnalysis/strings-and-files/.git'),\n",
       " WindowsPath('C:/Users/F0040RP/Documents/DartLib_RDS/textAnalysis/strings-and-files/.gitmodules'),\n",
       " WindowsPath('C:/Users/F0040RP/Documents/DartLib_RDS/textAnalysis/strings-and-files/.ipynb_checkpoints'),\n",
       " WindowsPath('C:/Users/F0040RP/Documents/DartLib_RDS/textAnalysis/strings-and-files/README.md'),\n",
       " WindowsPath('C:/Users/F0040RP/Documents/DartLib_RDS/textAnalysis/strings-and-files/state-of-the-union-dataset'),\n",
       " WindowsPath('C:/Users/F0040RP/Documents/DartLib_RDS/textAnalysis/strings-and-files/W23_PythonTA1_WorkingWithStringsAndFiles.ipynb')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path.iterdir(Path.cwd()))\n",
    "#os.listdir()\n",
    "\n",
    "#Do you see the \"sotu folder in the list below?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a2bef",
   "metadata": {},
   "source": [
    "3. Next, we will look inside the \"sotu\" folder containing our corpus of State of the Union speeches (henceforth: SOTU). We can learn something about this dataset simply by examining the titles of the individual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996fb8f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'sotu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13948\\188055103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msotudir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sotu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(list(Path.iterdir(sotudir))) #to get fullpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msotudir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#get unique suffixes or file extensions in sotudir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msotudir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#to get filename only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0mpaths\u001b[0m \u001b[1;34m'.'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \"\"\"\n\u001b[1;32m-> 1160\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m                 \u001b[1;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'sotu'"
     ]
    }
   ],
   "source": [
    "sotudir=Path(\"sotu\")\n",
    "#print(list(Path.iterdir(sotudir))) #to get fullpath\n",
    "print(set([item.suffix for item in list(Path.iterdir(sotudir))]))  #get unique suffixes or file extensions in sotudir \n",
    "[item.name for item in list(Path.iterdir(sotudir))] #to get filename only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e842155",
   "metadata": {},
   "source": [
    "## Part IV: Reading Files and Examining Their Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69bed1",
   "metadata": {},
   "source": [
    "1. Open one SOTU text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"sotu\",\"Bush_2002.txt\"),encoding='utf-8') as f:\n",
    "    bush02 = f.read()\n",
    "\n",
    "## ** calling utf-8 encoding may not be necessary\n",
    "## but is good practice if you ever work with foreign languages (besides special characters can appear in English too, as in \n",
    "## loan words like naïve and résumé )\n",
    "\n",
    "\n",
    "##[DISCUSS WHY IT IS GOOD PRACTICE TO CLOSE FILES IMMEDIATELY AFTER YOU ARE DONE WITH THEM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd517a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can view the whole text simply by typing the file name\n",
    "bush02  #Jupyter, however, requires the print() command to print out any information not found in the last line of code in a codeblock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3869fab",
   "metadata": {},
   "source": [
    "2. What do the following blocks of code do? Run them and then share your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb572c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bush02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bush02[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bush02[:20]  #this is exactly the same as bush02[0:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af841841",
   "metadata": {},
   "outputs": [],
   "source": [
    "bush02[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "bush02[-60:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea6db3",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\">Exercises for Part IV</h3>\n",
    "    \n",
    "<p style=\"color:blue;\">1. Add a coding cell below and print out the first and last 200 characters in the Bush 02 speech.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b38daa",
   "metadata": {},
   "source": [
    "### IVb. Divide a text into tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0976cefb",
   "metadata": {},
   "source": [
    "<p style = \"color:green\">The <b>split()</b> function allows us to divide a string by a delimiter. The default delimiter is a single space(\" \"). Let's split the following two items: a sentence and a series of phone numbers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = \"This is a simple sentence; or maybe not, as it contains multiple clauses - and different forms of punctuation.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonenums = \"555-755-8340, 555-831-2911, 555-442-9182\"\n",
    "phonenums.split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2727dd7",
   "metadata": {},
   "source": [
    "We can \"tokenize\" this SOTU text using the core Python function \"split()\". See the results below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtokens=bush02.split()\n",
    "print(rawtokens[:30])\n",
    "print(len(rawtokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f0739c",
   "metadata": {},
   "source": [
    "Notice this just splits words separated by spaces. It does not remove punctuation or split hyphenated words. See, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawtokens[:10])\n",
    "# notice the punctuation after the 4th and 6th tokens should be placed in separate tokens, while the \n",
    "# punctuation after Mr. needs to stay as it identifies it as an abbreviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e8d16",
   "metadata": {},
   "source": [
    "Fortunately, the text analysis package, \"NLTK\", offers a more sophisticated way to tokenize the words of a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(bush02)\n",
    "print(tokens[0:30]) #notice the difference between these tokens and \"rawtokens\" above\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to tokenize\n",
    "from nltk import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens2=tokenizer.tokenize(bush02)\n",
    "print(tokens2[:30])\n",
    "print(len(tokens2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33067517",
   "metadata": {},
   "source": [
    "<h3 style=\"color:purple\">Python Basics (Additional Practice): Data Types</h3>\n",
    "\n",
    "<ol style=\"color:purple\">\n",
    "    Select on the links below for more practice with...\n",
    "    <li>Lists and Tuples (and For Loops)</li>\n",
    "    <li>Dictionaries</li>\n",
    "    <li>Data Frames</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce643d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "105cfda2",
   "metadata": {},
   "source": [
    "<h3 style=\"color:purple\">Python Basics (Additional Practice): Working with File Names</h3>\n",
    "\n",
    "<p style=\"color:purple\">A good text corpus usually will include some metadata describing some basic information about the texts included. Sometimes this metadata will be stored in separate files and sometimes at the beginning of a text file. Our SOTU dataset, however, does not include any metadata - with one exception: information about the President and year in which he gave the addresss is store in the filename.</p>\n",
    "\n",
    "<p style=\"color:purple\">Here, we will use some basic Python commands to retrieve information from these file names.</p>\n",
    "\n",
    "<p style=\"color:purple\">1. Retrieve the name of the first file in the folder.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = sotudir.glob('*.txt')\n",
    "pathnames=[path.name for path in pathlist]\n",
    "print(pathnames[:10])\n",
    "firstfilename=pathnames[0]   #Note: in Python the first item of a list is given the index 0 not 1!\n",
    "print(firstfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b0dd6",
   "metadata": {},
   "source": [
    "<p style=\"color:purple\">2. We can then divide the filename into its three parts: president's name, year of address, and file type/extension.</p>\n",
    "\n",
    "<p style=\"color:purple\">We can do this in two steps using Python's core split() function, dividing the full file name first by \".\" and then by \"_\".</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(firstfilename)\n",
    "filename=firstfilename.split(\".\") #this line of code separates the filename into a list of parts that precede or follow a \".\"\n",
    "print(filename)\n",
    "filenameparts=filename[0].split(\"_\") #same thing, but using \"_\" as a separator\n",
    "print(filenameparts)\n",
    "ftype=filename[1]\n",
    "pres=filenameparts[0]\n",
    "year=filenameparts[1]\n",
    "print(\"President\",pres,\"delivered this State of the Union Address in\",year,\".\",\"This address is stored as a\",ftype,\"file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2abc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "213c4efe",
   "metadata": {},
   "source": [
    "## V: Iterating through lists using for loops\n",
    "\n",
    "<h3 style=\"color:green\">Code Together: Working with Lists</h3>\n",
    "\n",
    "**For loops** provide a simple means to iterate or cycle through items in a list, whether each item be a single value, an entire book or file, or a large directory of files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b19e9",
   "metadata": {},
   "source": [
    "<p style=\"color:green\">Below, we will create a list, perform some calculations on it, create a new empty list, and then add items to this new list.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "numlist=[1,2,3,4,5]\n",
    "print(numlist)\n",
    "print(len(numlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numlist.append(6)\n",
    "print(numlist)\n",
    "print(len(numlist))\n",
    "print(sum(numlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc6c8f",
   "metadata": {},
   "source": [
    "<p style='color:green'>We can use **for loops** to iterate through a list. and then populate a new, empty list based on calculations performed on the original list.  <i>Run this code and then modify it to take each number to the third power.</i></p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e66b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlist = []\n",
    "\n",
    "for num in numlist:\n",
    "    sq = num ** 2  #in Python \"*\" signifies multiplication and \"**\" signifies exponents, in this case \"num\" is taken to the 2nd power\n",
    "    sqlist.append(sq)\n",
    "print(sqlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a8cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541, 547, 557, 563, 569, 571, 577, 587, 593, 599, 601, 607, 613, 617, 619, 631, 641, 643, 647, 653, 659, 661, 673, 677, 683, 691, 701, 709, 719, 727, 733, 739, 743, 751, 757, 761, 769, 773, 787, 797, 809, 811, 821, 823, 827, 829, 839, 853, 857, 859, 863, 877, 881, 883, 887, 907, 911, 919, 929, 937, 941, 947, 953, 967, 971, 977, 983, 991, 997, 1009, 1013, 1019, 1021, 1031, 1033, 1039, 1049, 1051, 1061, 1063, 1069, 1087, 1091, 1093, 1097, 1103, 1109, 1117, 1123, 1129, 1151, 1153, 1163, 1171, 1181, 1187, 1193, 1201, 1213, 1217, 1223, 1229, 1231, 1237, 1249, 1259, 1277, 1279, 1283, 1289, 1291, 1297, 1301, 1303, 1307, 1319, 1321, 1327, 1361, 1367, 1373, 1381, 1399, 1409, 1423, 1427, 1429, 1433, 1439, 1447, 1451, 1453, 1459, 1471, 1481, 1483, 1487, 1489, 1493, 1499, 1511, 1523, 1531, 1543, 1549, 1553, 1559, 1567, 1571, 1579, 1583, 1597, 1601, 1607, 1609, 1613, 1619, 1621, 1627, 1637, 1657, 1663, 1667, 1669, 1693, 1697, 1699, 1709, 1721, 1723, 1733, 1741, 1747, 1753, 1759, 1777, 1783, 1787, 1789, 1801, 1811, 1823, 1831, 1847, 1861, 1867, 1871, 1873, 1877, 1879, 1889, 1901, 1907, 1913, 1931, 1933, 1949, 1951, 1973, 1979, 1987, 1993, 1997, 1999, 2003, 2011, 2017, 2027, 2029, 2039, 2053, 2063, 2069, 2081, 2083, 2087, 2089, 2099, 2111, 2113, 2129, 2131, 2137, 2141, 2143, 2153, 2161, 2179, 2203, 2207, 2213, 2221, 2237, 2239, 2243, 2251, 2267, 2269, 2273, 2281, 2287, 2293, 2297, 2309, 2311, 2333, 2339, 2341, 2347, 2351, 2357, 2371, 2377, 2381, 2383, 2389, 2393, 2399, 2411, 2417, 2423, 2437, 2441, 2447, 2459, 2467, 2473, 2477, 2503, 2521, 2531, 2539, 2543, 2549, 2551, 2557, 2579, 2591, 2593, 2609, 2617, 2621, 2633, 2647, 2657, 2659, 2663, 2671, 2677, 2683, 2687, 2689, 2693, 2699, 2707, 2711, 2713, 2719, 2729, 2731, 2741, 2749, 2753, 2767, 2777, 2789, 2791, 2797, 2801, 2803, 2819, 2833, 2837, 2843, 2851, 2857, 2861, 2879, 2887, 2897, 2903, 2909, 2917, 2927, 2939, 2953, 2957, 2963, 2969, 2971, 2999, 3001, 3011, 3019, 3023, 3037, 3041, 3049, 3061, 3067, 3079, 3083, 3089, 3109, 3119, 3121, 3137, 3163, 3167, 3169, 3181, 3187, 3191, 3203, 3209, 3217, 3221, 3229, 3251, 3253, 3257, 3259, 3271, 3299, 3301, 3307, 3313, 3319, 3323, 3329, 3331, 3343, 3347, 3359, 3361, 3371, 3373, 3389, 3391, 3407, 3413, 3433, 3449, 3457, 3461, 3463, 3467, 3469, 3491, 3499, 3511, 3517, 3527, 3529, 3533, 3539, 3541, 3547, 3557, 3559, 3571, 3581, 3583, 3593, 3607, 3613, 3617, 3623, 3631, 3637, 3643, 3659, 3671, 3673, 3677, 3691, 3697, 3701, 3709, 3719, 3727, 3733, 3739, 3761, 3767, 3769, 3779, 3793, 3797, 3803, 3821, 3823, 3833, 3847, 3851, 3853, 3863, 3877, 3881, 3889, 3907, 3911, 3917, 3919, 3923, 3929, 3931, 3943, 3947, 3967, 3989, 4001, 4003, 4007, 4013, 4019, 4021, 4027, 4049, 4051, 4057, 4073, 4079, 4091, 4093, 4099, 4111, 4127, 4129, 4133, 4139, 4153, 4157, 4159, 4177, 4201, 4211, 4217, 4219, 4229, 4231, 4241, 4243, 4253, 4259, 4261, 4271, 4273, 4283, 4289, 4297, 4327, 4337, 4339, 4349, 4357, 4363, 4373, 4391, 4397, 4409, 4421, 4423, 4441, 4447, 4451, 4457, 4463, 4481, 4483, 4493, 4507, 4513, 4517, 4519, 4523, 4547, 4549, 4561, 4567, 4583, 4591, 4597, 4603, 4621, 4637, 4639, 4643, 4649, 4651, 4657, 4663, 4673, 4679, 4691, 4703, 4721, 4723, 4729, 4733, 4751, 4759, 4783, 4787, 4789, 4793, 4799, 4801, 4813, 4817, 4831, 4861, 4871, 4877, 4889, 4903, 4909, 4919, 4931, 4933, 4937, 4943, 4951, 4957, 4967, 4969, 4973, 4987, 4993, 4999, 5003, 5009, 5011, 5021, 5023, 5039, 5051, 5059, 5077, 5081, 5087, 5099, 5101, 5107, 5113, 5119, 5147, 5153, 5167, 5171, 5179, 5189, 5197, 5209, 5227, 5231, 5233, 5237, 5261, 5273, 5279, 5281, 5297, 5303, 5309, 5323, 5333, 5347, 5351, 5381, 5387, 5393, 5399, 5407, 5413, 5417, 5419, 5431, 5437, 5441, 5443, 5449, 5471, 5477, 5479, 5483, 5501, 5503, 5507, 5519, 5521, 5527, 5531, 5557, 5563, 5569, 5573, 5581, 5591, 5623, 5639, 5641, 5647, 5651, 5653, 5657, 5659, 5669, 5683, 5689, 5693, 5701, 5711, 5717, 5737, 5741, 5743, 5749, 5779, 5783, 5791, 5801, 5807, 5813, 5821, 5827, 5839, 5843, 5849, 5851, 5857, 5861, 5867, 5869, 5879, 5881, 5897, 5903, 5923, 5927, 5939, 5953, 5981, 5987, 6007, 6011, 6029, 6037, 6043, 6047, 6053, 6067, 6073, 6079, 6089, 6091, 6101, 6113, 6121, 6131, 6133, 6143, 6151, 6163, 6173, 6197, 6199, 6203, 6211, 6217, 6221, 6229, 6247, 6257, 6263, 6269, 6271, 6277, 6287, 6299, 6301, 6311, 6317, 6323, 6329, 6337, 6343, 6353, 6359, 6361, 6367, 6373, 6379, 6389, 6397, 6421, 6427, 6449, 6451, 6469, 6473, 6481, 6491, 6521, 6529, 6547, 6551, 6553, 6563, 6569, 6571, 6577, 6581, 6599, 6607, 6619, 6637, 6653, 6659, 6661, 6673, 6679, 6689, 6691, 6701, 6703, 6709, 6719, 6733, 6737, 6761, 6763, 6779, 6781, 6791, 6793, 6803, 6823, 6827, 6829, 6833, 6841, 6857, 6863, 6869, 6871, 6883, 6899, 6907, 6911, 6917, 6947, 6949, 6959, 6961, 6967, 6971, 6977, 6983, 6991, 6997, 7001, 7013, 7019, 7027, 7039, 7043, 7057, 7069, 7079, 7103, 7109, 7121, 7127, 7129, 7151, 7159, 7177, 7187, 7193, 7207, 7211, 7213, 7219, 7229, 7237, 7243, 7247, 7253, 7283, 7297, 7307, 7309, 7321, 7331, 7333, 7349, 7351, 7369, 7393, 7411, 7417, 7433, 7451, 7457, 7459, 7477, 7481, 7487, 7489, 7499, 7507, 7517, 7523, 7529, 7537, 7541, 7547, 7549, 7559, 7561, 7573, 7577, 7583, 7589, 7591, 7603, 7607, 7621, 7639, 7643, 7649, 7669, 7673, 7681, 7687, 7691, 7699, 7703, 7717, 7723, 7727, 7741, 7753, 7757, 7759, 7789, 7793, 7817, 7823, 7829, 7841, 7853, 7867, 7873, 7877, 7879, 7883, 7901, 7907, 7919, 7927, 7933, 7937, 7949, 7951, 7963, 7993, 8009, 8011, 8017, 8039, 8053, 8059, 8069, 8081, 8087, 8089, 8093, 8101, 8111, 8117, 8123, 8147, 8161, 8167, 8171, 8179, 8191, 8209, 8219, 8221, 8231, 8233, 8237, 8243, 8263, 8269, 8273, 8287, 8291, 8293, 8297, 8311, 8317, 8329, 8353, 8363, 8369, 8377, 8387, 8389, 8419, 8423, 8429, 8431, 8443, 8447, 8461, 8467, 8501, 8513, 8521, 8527, 8537, 8539, 8543, 8563, 8573, 8581, 8597, 8599, 8609, 8623, 8627, 8629, 8641, 8647, 8663, 8669, 8677, 8681, 8689, 8693, 8699, 8707, 8713, 8719, 8731, 8737, 8741, 8747, 8753, 8761, 8779, 8783, 8803, 8807, 8819, 8821, 8831, 8837, 8839, 8849, 8861, 8863, 8867, 8887, 8893, 8923, 8929, 8933, 8941, 8951, 8963, 8969, 8971, 8999, 9001, 9007, 9011, 9013, 9029, 9041, 9043, 9049, 9059, 9067, 9091, 9103, 9109, 9127, 9133, 9137, 9151, 9157, 9161, 9173, 9181, 9187, 9199, 9203, 9209, 9221, 9227, 9239, 9241, 9257, 9277, 9281, 9283, 9293, 9311, 9319, 9323, 9337, 9341, 9343, 9349, 9371, 9377, 9391, 9397, 9403, 9413, 9419, 9421, 9431, 9433, 9437, 9439, 9461, 9463, 9467, 9473, 9479, 9491, 9497, 9511, 9521, 9533, 9539, 9547, 9551, 9587, 9601, 9613, 9619, 9623, 9629, 9631, 9643, 9649, 9661, 9677, 9679, 9689, 9697, 9719, 9721, 9733, 9739, 9743, 9749, 9767, 9769, 9781, 9787, 9791, 9803, 9811, 9817, 9829, 9833, 9839, 9851, 9857, 9859, 9871, 9883, 9887, 9901, 9907, 9923, 9929, 9931, 9941, 9949, 9967, 9973]\n"
     ]
    }
   ],
   "source": [
    "primes = []\n",
    "for i in range(1,10000):\n",
    "    if not i>2:\n",
    "        primes.append(i)\n",
    "        continue\n",
    "    lowerNums = range(2,i)\n",
    "    isPrime = True\n",
    "    for lnum in lowerNums:\n",
    "        if i % lnum == 0:\n",
    "            isPrime = False\n",
    "            break\n",
    "    if isPrime:\n",
    "        primes.append(i)\n",
    "print(primes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7e9e2",
   "metadata": {},
   "source": [
    "<p style='color:green'>An example applying some basic string functions to a list of strings:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b7fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "george r. r. martin\n",
      "GEORGE R. R. MARTIN\n",
      "by George R. R. Martin\n",
      "19\n",
      "['George', 'R.', 'R.', 'Martin']\n",
      "('Martin', 'George R. R.')\n",
      "\n",
      "\n",
      "\n",
      "***\n",
      "chimamanda ngozi adichie\n",
      "CHIMAMANDA NGOZI ADICHIE\n",
      "by Chimamanda Ngozi Adichie\n",
      "24\n",
      "['Chimamanda', 'Ngozi', 'Adichie']\n",
      "('Adichie', 'Chimamanda Ngozi')\n",
      "\n",
      "\n",
      "\n",
      "***\n",
      "margaret atwood\n",
      "MARGARET ATWOOD\n",
      "by Margaret Atwood\n",
      "15\n",
      "['Margaret', 'Atwood']\n",
      "('Atwood', 'Margaret')\n",
      "\n",
      "\n",
      "\n",
      "***\n",
      "louise erdrich\n",
      "LOUISE ERDRICH\n",
      "by Louise Erdrich\n",
      "14\n",
      "['Louise', 'Erdrich']\n",
      "('Erdrich', 'Louise')\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authors=[\"George R. R. Martin\",\"Chimamanda Ngozi Adichie\",\"Margaret Atwood\",\"Louise Erdrich\"]\n",
    "for author in authors:\n",
    "    print(\"***\")\n",
    "    print(author.lower())  #some examples of some simple string functions, observe what they do!\n",
    "    print(author.upper())\n",
    "    print(\"by \"+author)\n",
    "    print(len(author))\n",
    "    names=author.split()\n",
    "    print(names)\n",
    "    print((names[-1],' '.join(names[:-1])))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30e6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "979919c1",
   "metadata": {},
   "source": [
    "## VI. How many Roosevelts?: For Loop to iterate through files\n",
    "\n",
    "We can also use a **for loop** to iterate through all our SOTU files and count only those that fit a certain criteria (i.e. files that are .txt or .csv files, files that start with or end with a specific set of characters, or contain particular information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccde5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudir=Path(\"sotu\") #I already defined sotudir above, but re-inserting here for anyone skipping around\n",
    "pathlist = sotudir.glob('*.txt') #returns a list of all .txt files from the filepath we saved as \"sotudir\"\n",
    "\n",
    "for path in pathlist:\n",
    "    # print(path)        \n",
    "    print(path.name)\n",
    "\n",
    "#print([path.name for path in pathlist])  #this is a list comprehension version of the above code\n",
    "## experienced Python programmers prefer list comprehensions over for loops, but for loops are nice, \n",
    "##    very human-readable code that works well for beginners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313008af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16765ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist = sotudir.glob('*.txt') # .glob only stores the pathlist temporarily (for some reason), so you need to call it again!\n",
    "ctr=0\n",
    "for path in pathlist:\n",
    "    filename=path.name\n",
    "    if filename.startswith(\"Roosevelt\"):\n",
    "        print(filename)\n",
    "        ctr+=1\n",
    "print(ctr,\"SOTU addresses by a Roosevelt (FDR or Theodore) are included in this corpus\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8338ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy and paste the above code, but this time calculate the number of SOTU addresses delivered by a Bush."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f7bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b6ac239",
   "metadata": {},
   "source": [
    "## Part VII: Creating a graph of the SOTU speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.tokenize import RegexpTokenizer #<--necessary only if you didn't run this above\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "txtList=[]\n",
    "sotudir2=Path(\"sotu2\")\n",
    "pathlist = sotudir2.glob('*.txt') # .glob only stores the pathlist temporarily (for some reason), so you need to call it again!2\n",
    "ctr=0\n",
    "for path in pathlist:\n",
    "    fn=path.stem\n",
    "    fileType=path.suffix\n",
    "    year,pres=fn.split(\"_\")\n",
    "    with open(path,'r') as f:  \n",
    "        sotu = f.read()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens=tokenizer.tokenize(sotu)\n",
    "    numWords=len(tokens)\n",
    "    txtList.append([pres,year,numWords,tokens])\n",
    "\n",
    "colnames=['pres','year','numWords','tokens']\n",
    "sotudf=pd.DataFrame(txtList,columns=colnames)  ##\n",
    "sotudf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotudf['year'] = sotudf['year'].astype(int)\n",
    "sotuSub = sotudf[['pres','year','numWords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641795e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotuSub.to_csv(\"sotuList.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4badaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=sotuSub, x=\"year\", y=\"numWords\", palette = \"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04960096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g=sns.barplot(data=sotuSub, x=\"year\", y=\"numWords\", hue = \"pres\",dodge = False, palette = \"colorblind\")\n",
    "g.tick_params(labelrotation=90)\n",
    "\n",
    "#https://github.com/mwaskom/seaborn/issues/970\n",
    "#Add attribute dodge=False\n",
    "#Instead of creating different bar for single value. Adding dodge=False shows the data in single bar per variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eafa48",
   "metadata": {},
   "source": [
    "One problem: there are too many labels on the x-axis. Run the following code. The line that begins with \"plt.xticks\" places x axis tick labels only at every ten years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "startYr = sotuSub['year'][0]\n",
    "endYr = sotuSub['year'][len(sotuSub['year'])-1]\n",
    "decades = [i for i in range(int(startYr),int(endYr)+1) if i % 10 == 0]\n",
    "\n",
    "f, ax = plt.subplots(figsize = (20,15))\n",
    "sns.barplot(data=sotuSub, x=\"year\", y=\"numWords\", hue = \"pres\",dodge = False, palette = \"colorblind\")\n",
    "ax.tick_params(labelrotation=90)\n",
    "#ax.set(xticks = decades)\n",
    "plt.xticks([dec - 1790 for dec in decades],labels=decades)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07047f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf283149",
   "metadata": {},
   "source": [
    "Let's modify the graph by labeling and grouping each bar by president.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4b94e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Final Exercise</h2>\n",
    "\n",
    "<p style=\"color:blue\">2. (advanced). Return a count and the filenames of all SOTU addresses delivered in the nineteenth century. Hint: you will probably need to use an index of filenames to isolate the century (the first two digits of each SOTU file year). Review Lesson 1, Part 1b for clues how to do this.</p>\n",
    "\n",
    "<p style=\"color:blue\">If you are unable to complete this or just want to compare, code is available in the completed version of this notebook (suffix: \"_completed.ipynb\")</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddf224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
